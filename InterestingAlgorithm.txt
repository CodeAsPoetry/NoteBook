第1章：算法之美

1. 考查算法的最坏情况对衡量算法的好坏具有实际的意义。

2. 算法运行需要时需要的辅助空间是衡量空间复杂度的关键因素。

3. 递归调用，包括递推和回归。递推是将原问题不断分解成子问题，直到达到结束条件，返回最近子问题的解；然后逆向逐一回归，最终到达递推开始的原问题，返回原问题的解。

4. O(2^n)<O(n!)<O(n^n)

5. 特征方程和通项公式的推导：详见个人博客https://codeaspoetry.github.io/

6. 斐波那契数列时间复杂度/空间复杂度：O(常数^n)/O(1)，O(n)/O(n)，O(n)/O(1)，（待考查）O(log n)/未知。

7. 心得：真的被斐波那契数列的美震撼了，瞬间想买《数学之美》看看。。。。。。。。。。。。。。。。。。。。。。。。。。

6. 取模：求商时向负无穷方向舍入；取余：求商时向0方向舍入 -7对4取余为-3；-7对4取模为+1

7. 哥德巴赫猜想：任一大于2的偶数，都可表示成两个素数之和


第二章：贪心算法

1. 一个贪心算法总是做出当前最好的选择，也就是说，它期望通过局部最优选择从而得到全局最优的解决方案。————《算法导论》

2. 利用贪心算法求解的问题往往具有两个重要的特性：贪心选择性质和最优子结构性质。

3. 选择排序、冒泡排序使用了贪心算法。

4. 物品可分割的装载问题称为背包问题，物品不可分割的装载问题称为0-1背包问题。

5. 加勒比海盗(选择最轻的)、阿里巴巴与四十大盗(可以分割，选择性价比最高的)、会议安排(选择具有最早结束时间且与已安排的会议相容的会议安排)、最短路径

6. Edsger Wybe Dijkstra和Donald Ervin Knuth并称为我们这个时代最伟大的计算机科学家。

7. Dijkstra算法：解决单源最短路径问题的贪心算法。(这是我见到的最透彻的讲解)

8. 寻常的Dijkstra算法时间复杂度O(n^2),空间复杂度O(n)；经优先队列优化，且换用邻接表存储，时间复杂度可将为O(E*log n)，如果用斐波那契堆，松弛操作的时间复杂度O(1)，总的时间复杂度为O(n*log n + E)。(再次被斐波那契惊呆了，有木有？)

9. 优先队列具有最高级先出的行为特征。

10. 如果每个字符的使用频率相等，固定长度编码是空间效率最高的方法。

11. 哈夫曼算法采取的贪心策略是每次从树的集合中取出没有双亲且权值最小的两棵树作为左右子树

12. 最小生成树：对于n个顶点的连通图，只需n-1条边就可以使这个图连通，n-1条边要想保证图连通，就必须不含回路，所以我们只需要找出n-1条权值最小且无回路的边即可。

13. 避圈法，在一个图中深度搜索或广度搜索有没有回路。在生成树的过程中，把已经在生成树中的结点看作一个集合，把剩下的结点看作另一个集合，从连接两个集合的边中选择一条权值最小的边即可。这就是Prim算法：1957年由美国计算机科学家Robert C.Prim发现。

14. Kruskal算法：将所有边按照权值从小到大排序，选取权值最小的边，不产生回路，加入最小生成树的边集合T中；否则，选取下一条最短边。采用集合避圈：如果所选择加入的边的起点和终点都在T集合中，那么就可以断定一定会形成回路(圈)。合并集合的时间复杂度是O(n^2)，用并查集的思想优化，可降为O(e*log n)。

15. 并查集：两个元素集合号不同，合并时，擒贼先擒王，只改祖宗即可，并不需要把集合中所有结点都检索一遍并修改。

第三章：分治法

1. 分治算法：本质就是将一个大规模的问题分解为若干个规模较小的相同子问题，分而治之，递归是彰显分治法优势的利器。

2. 二分搜索技术、合并排序：合久必分，分久必合、快速排序：由C.A.R.Hoare在1962年提出。

3. 以选取第一个元素做基准为例，快速排序的执行过程：
假设当前待排序的序列为R[low:high]，其中low<=high。
1>.首先取数组的第一个元素作为基准元素pivot=R[low]，i=low，j=high。
2>.从右向左扫描，找小于等于pivot的数，如果找到，R[i]和R[j]交换，i++。
3>.从左向右扫描，找大于pivot的数，如果找到，R[i]和R[j]交换，j--。
4>.重复步骤2~3，直到i和j指针重合，返回该位置mid=i，该位置的数正好是pivot元素。
至此完成一趟排序，此时以mid为界，将原数据分为两个子序列，左侧子序列元素都比pivot小，右侧子序列元素都比pivot大，然后再分别对这两个子序列进行快速排序。

4. 针对3进行优化，无需每次都和基准元素交换，减少交换次数：
假设当前待排序的序列为R[low:high]，其中low<=high。
1>.首先取数组的第一个元素作为基准元素pivot=R[low]，i=low，j=high。
2>.从右向左扫描，找小于等于pivot的数R[i]。
3>.从左向右扫描，找大于pivot的数R[j].
4>.R[i]和R[j]交换，i++，j--。
5>.重复步骤2~4，直到i和j相等，如果R[i]大于pivot，则R[i-1]和基准元素R[low]交换，返回该位置mid=i-1；否则，R[i]和基准元素R[low]交换，返回该位置mid=i，该位置的数正好是基准元素。
至此完成一趟排序，此时以mid为界，将原数据分为两个子序列，左侧子序列元素都比pivot小，右侧子序列元素都比pivot大，然后再分别对这两个子序列进行快速排序。

5. 大整数相乘，优化：四次乘法优化至三次(高斯) (关于大整数相乘具体运算实现理解得还不是很透彻)

6. 分治算法复杂度求解：递归树求解法、大师解法(理解得还是不够透彻)

第四章：动态规划

1. 分治法是将原问题分解为若干个规模较小、形式相同的子问题，然后求解这些子问题，合并子问题的解得到原问题的解。在分治法中，各个子问题是互不相交的，即相互独立。如果各个子问题有重叠，不是相互独立的，那么用分治法就重复求解了很多子问题，根本显现不了分治的优势，反而降低了算法效率。动态规划就解决此问题。

2. 动态规划是1957年理查德.贝尔曼在《Dynamic Programming》提出，他还和莱斯特.福特一起提出了求解最短路径的Bellman-Ford算法，该算法解决了Dijkstra算法不能处理的负权值边的问题。Dynamic Programming中的Programming不是编程的意思，而是指一种表格处理法。把每一步得到的子问题结果存储在表格里，每次遇到该子问题时不需要再求解一遍，只需要查询表格即可。

3. 当问题具有最优子结构，即问题的最优解包含其子问题的最优解时，才可使用动态规划解决，并且如果子问题重叠，只求解一次存储在表中，以后使用可以直接查询，无需再次求解，更能够充分彰显动态规划的优势。

4. 遇到一个实际问题，采用动态规划解决步骤：
1>.分析最优解的结构特征
2>.建立最优值的递归式
3>.自底向上计算最优值，并记录
4>.构造最优解

5. 动态规划的难点在于很难找到相应的递归式。

6. 动态规划求解两个字符串的最长公共子序列。

7. 编辑距离是指将一个字符串变换为另一个字符串所需要的最小编辑操作，满足动态规划的最优子结构性质，可以自底向上逐渐推出整体最优解。

8. 动态规划解决长江一日游————游艇租赁

9. 动态规划解决矩阵连乘、凸多边形的最优三角剖分、石子合并(直线玩法、圆圈玩法(可以转换为2n-1规模的直线玩法))

10. 利用普通动态规划解决石子合并，时间复杂度为O(n^3)；可以通过四边形不等式将最小值求解优化至O(n^2)时间复杂度，而最大值求解有在端点处取到的性质也可以优化到O(n^2)。(理解得还不太透彻)

11. 动态规划解决0-1背包问题，时间复杂度O(n*W)，空间复杂度由二维矩阵c[n][W]造成，也为O(n*W)。可以通过反推j，优化，使第i次循环结束后dp[j]中表示的就是定义的状态c[i][j]。

12. 动态规划解决最优二叉树搜索，也可以用四边形不等式优化。

第五章：回溯法

1. 解题秘籍：定义解空间、确定解空间的组织结构、搜索解空间。回溯法解题的关键是设计有效的显约束和隐约束。显约束是对解分量的取值范围的限定，隐约束指对能否得到问题的可行解或最优解做出的约束，隐约束也称为剪枝函数，包括约束函数和限界函数。

2. 回溯法解决0-1背包问题，可以把“已装入的和剩余的价值之和作为上界函数”通过当前价值加上可容纳的剩余物品的最大价值(考虑可切割的性价比)作为上界函数进行优化

3. 回溯法解决最大团问题。完全子图、团、最大团

4. 回溯法解决图的m着色问题：给定无向连通图G和m种颜色，找出所有不同的着色方案，使相邻的区域有不同的颜色。因为要求所有的可行解，所以只有约束函数，无需限界函数。




